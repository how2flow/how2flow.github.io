---
permalink: /posts/npu/
title: "ODROID-M1, NPU 사용해 보기 (yolov5)"
excerpt: "ODROID-M1은 저렴한 가격에 NPU를 사용할 수 있는 좋은 선택입니다."
header:
  teaser: /assets/posts/images/odroid-m1.jpg/
categories:
  - Linux
tags:
  - ai
  - machine-learning
  - npu
  - odroid
toc: true
---

## intro

최근 가장 핫한 주제 중에 하나인 AI와 머신러닝으로 포스팅 합니다.<br>
머신러닝 프로그램이 발전됨에 따라, 하드웨어도 부하가 많이 걸리게 되고,<br>
필연적으로 성능향상을 위해 제품이 개발됩니다.<br>

대표적으로 <span style="{{ site.code }}">NPU</span> (**N**eural **P**rocessing **U**nit)가 그렇습니다.<br>
NPU 자체가 기존의 CPU, GPU보다 성능이 월등히 좋다 이런건 아니고..<br>
머신러닝 연산에 최적화된 하드웨어라고 보면 됩니다.<br>
물리적으로 성능자체를 끌어올리는 것은 가능한 부분은 이미 다 되어 있거든요<br>

아무튼 NPU를 지원하는 SBC 중에서 가격이 저렴하고 지금 제가 가지고 있는<br>
ODROID-M1을 가지고 머신러닝 모델을 돌려보겠습니다.<br>

[Wiki](https://wiki.odroid.com/odroid-m1/application_note/rknpu/manual)를 참조했습니다. ~~물론 내가 씀~~<br>

## 준비하기

소제목처럼 저렴한 가격으로 NPU를 사용할 수 있습니다.<br>

<p align="center">
  <img src="/assets/posts/images/odroid-m1.jpg/" alt="odroid-m1" width="640" height="480"><br>
  <span style="{{ site.img }}">[picture 1] ODROID-M1 </span>
</p>
<br>

ODROID-M1은 [여기](https://www.hardkernel.com/shop/odroid-m1-with-4gbyte-ram/)서 구매하면 됩니다.<br>
한화로 약 8~9만원대 가격이고 emmc카드 (32나 64GB 기준) 3~4 만원 정도니까 약 12~13만원 정도면 됩니다.<br>
M1의 rk3568 칩은 0.8Tops의 스펙을 가진 NPU가 내장 되어 있습니다.<br>

준비물 입니다.
```
- ODROID-M1 board x1
```

오드로이드 M1 이미지를 eMMC 카드에 굽고 보드를 부팅합니다.<br>

### Bypass petitboot

M1에서 NPU 사용전에 주의사항이 있습니다.<br>
다른 회사 제품들과 다르게 ODROID-M1은 petitboot를 지원하고 있습니다.<br>
<br>
<p align="center">
  <img src="/assets/posts/images/m1-bootsequence.png/" alt="m1-bootsequence" width="640" height="480"><br>
  <span style="{{ site.img }}">[picture 2] M1 bootsequence</span>
</p>
<br>

SPI ROM에 내장되어 있는 작은 리눅스 프로그램인데 NPU와 함께 사용할 수 없습니다.<br>
아마 power cycle에 문제가 있는듯 보입니다.<br>

M1을 처음 구매하면 기본적으로 petitboot가 활성화된 상태 입니다.<br>
<br>
<p align="center">
  <img src="/assets/posts/images/m1-petitboot.png/" alt="m1-petitboot" width="640" height="480"><br>
  <span style="{{ site.img }}">[picture 3] M1 petitboot</span>
</p>
<br>

위 사진처럼 <span style="{{ site.code }}">Exit to shell</span> 을 선택해서 다음 명령어를 입력해주세요
```
# fw_setenv skip_spiboot true
```
리부팅 하면 변경사항이 적용됩니다.<br>

### npu 오버레이 추가하기

M1의 NPU는 <span style="{{ site.code }}">rknpu</span> 라는 커널 모듈로 제공됩니다.<br>
rknpu 오버레이를 추가합니다.
```
$ sudo vi /boot/config.ini
```
```
[generic]
overlay_resize=16384
overlay_profile=
overlays="rknpu"

[overlay_custom]
overlays="i2c0 i2c1"

[overlay_hktft32]
overlays="hktft32 ads7846"
```

리부팅 합니다.<br>

### 의존성 확인하기

M1에서 제공하는 NPU에는 크게 두가지 의존성이 있습니다.<br>
<span style="{{ site.code }}">rkrga</span> 드라이버 버전과 <span style="{{ site.code }}">librga</span> 버전입니다.<br>
전자는 rga 드라이버 자체의 버전이고, 후자는 예제에서 사용할 rga 관련 라이브러리 버전입니다.<br>

버전 확인은 [공식 문서](https://github.com/airockchip/librga/blob/main/docs/Rockchip_Developer_Guide_RGA_EN.md)에서 확인할 수 있습니다.<br>
<br>
<p align="center">
  <img src="/assets/posts/images/m1-corr.ver.png/" alt="m1-corr.ver" width="640" height="480"><br>
  <span style="{{ site.img }}">[picture 4] correspondence between versions</span>
</p>
<br>

보드에서 <span style="{{ site.code }}">rkrga</span> 드라이버 버전을 확인해 보겠습니다.
```
$ sudo su
# cat /sys/kernel/debug/rkrga/driver_version
RGA2 Device Driver: v2.1.0
# exit
```

현재 드라이버 버전은 v2.1.0입니다.<br>
librga 버전을 1.0.0 ~ 1.3.2 버전을 사용하거나 1.4.0 버전 이상을 사용하면 될 것 같습니다.<br>

## 예제

예제 프로젝트를 다운로드 받고, 먼저 librga 버전을 확인합니다.
```
$ cd
$ git clone https://github.com/rockchip-linux/rknpu2.git
$ cd rknpu2/examples/3rdparty/rga/RK356X/lib/Linux/aarch64
$ strings librga.so | grep rga_api | grep version
rga_api version 1.9.1_[4]
```

1.9.1 버전이네요?<br>
<span style="{{ site.code }}">rknpu</span> 커널 드라이버를 올리고 librga가 rkrga 드라이버와 호환이 되는 버전이니 계속 진행합니다.
```
$ sudo modprobe rknpu
$ lsmod | grep rknpu
rknpu                  49152  0
```

### mobilenet

기본적으로 제공되는 <span style="{{ site.code }}">mobilenet</span> 예제 실행 방법입니다.
```
$ cd ~/rknpu2/examples/rknn_mobilenet_demo
$ sudo chmod +x build-linux_RK3566_RK3568.sh
$ ./build-linux_RK3566_RK3568.sh
$ cd install/rknn_mobilenet_demo_Linux
$ export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:./lib
$ sudo ./rknn_mobilenet_demo model/RK3566_RK3568/mobilenet_v1.rknn model/dog_224x224.jpg 
model input num: 1, output num: 1
input tensors:
  index=0, name=input, n_dims=4, dims=[1, 224, 224, 3], n_elems=150528, size=150528, fmt=NHWC, type=INT8, qnt_type=AFFINE, zp=0, scale=0.007812
output tensors:
  index=0, name=MobilenetV1/Predictions/Reshape_1, n_dims=2, dims=[1, 1001, 0, 0], n_elems=1001, size=1001, fmt=UNDEFINED, type=INT8, qnt_type=AFFINE, zp=-128, scale=0.003906
rknn_run
 --- Top5 ---
156: 0.984375
155: 0.007812
205: 0.003906
 -1: 0.000000
 -1: 0.000000
```

### yolov5

기본적으로 제공되는 <span style="{{ site.code }}">yolov5</span> 예제 실행 방법입니다.
```
$ cd ~/rknpu2/examples/rknn_yolov5_demo
$ sudo chmod +x build-linux_RK3566_RK3568.sh
$ ./build-linux_RK3566_RK3568.sh
$ cd install/rknn_yolov5_demo_Linux
$ export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:./lib
$ sudo ./rknn_yolov5_demo model/RK3566_RK3568/yolov5s-640-640.rknn model/bus.jpg
post process config: box_conf_threshold = 0.25, nms_threshold = 0.45
Read model/bus.jpg ...
img width = 640, img height = 640
Loading mode...
sdk version: 1.5.0 (e6fe0c678@2023-05-25T08:09:20) driver version: 0.8.8
model input num: 1, output num: 3
  index=0, name=images, n_dims=4, dims=[1, 640, 640, 3], n_elems=1228800, size=1228800, w_stride = 640, size_with_stride=1228800, fmt=NHWC, type=INT8, qnt_type=AFFINE, zp=-128, scale=0.003922
  index=0, name=269, n_dims=4, dims=[1, 255, 80, 80], n_elems=1632000, size=1632000, w_stride = 0, size_with_stride=1638400, fmt=NCHW, type=INT8, qnt_type=AFFINE, zp=83, scale=0.093136
  index=1, name=271, n_dims=4, dims=[1, 255, 40, 40], n_elems=408000, size=408000, w_stride = 0, size_with_stride=409600, fmt=NCHW, type=INT8, qnt_type=AFFINE, zp=48, scale=0.089854
  index=2, name=273, n_dims=4, dims=[1, 255, 20, 20], n_elems=102000, size=102000, w_stride = 0, size_with_stride=122880, fmt=NCHW, type=INT8, qnt_type=AFFINE, zp=46, scale=0.078630
model is NHWC input fmt
model input height=640, width=640, channel=3
once run use 49.735000 ms
loadLabelName ./model/coco_80_labels_list.txt
person @ (209 243 285 507) 0.883131
person @ (477 241 561 523) 0.866942
person @ (110 235 231 536) 0.825886
bus @ (92 129 553 466) 0.703667
person @ (80 354 121 516) 0.326333
loop count = 10 , average run  49.042100 ms
```

yolo 모델은 특정한 object를 학습하고 구분해내는 모델입니다.<br>
위 예제를 실행하면 다음과 같은 결과를 얻을 수 있습니다.<br>
<br>
<p align="center">
  <img src="/assets/posts/images/input-bus.jpg/" alt="input-bus" width="320" height="240">
  <img src="/assets/posts/images/output-bus.jpg/" alt="output-bus" width="320" height="240"><br>
  <span style="{{ site.img }}">[picture 5] Result of yolov5 demo</span>
</p>
<br>

버스와 사람들을 구분해서 box를 쳤습니다.<br>
사진에 흐릿해서 잘 안보이는데 box 상단에 작게 "person 88.3%" 이런 식으로 텍스트가 있습니다.<br>
모델을 10회 실행하고 걸린시간의 평균은 49.04ms 입니다.<br>

## 커스텀 모델 사용하기

추후에 커스텀 모델을 사용하는 포스팅을 진행하겠습니다.<br>
roboflow에서 yolov5 모델 하나 가져와서 예시를 보여드리겠습니다.<br>
사실 이미 [Wiki](https://wiki.odroid.com/odroid-m1/application_note/rknpu/run_custom_model_yolov5)에 있는 내용이긴 합니다만 좀 보기 어려울 수 있습니다.. ~~역시 내가 씀~~<br>
